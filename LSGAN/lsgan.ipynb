{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#import tensorflow as tf\n#tf.__version__\n#!conda install -y gdown\n#!gdown --id 13t7OBZ1_cyQySXgyTgiIQVP6mu3DBJlT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard\n%matplotlib inline\n\nimport io\nimport os\nimport argparse\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport IPython.display as display\nimport imageio\nimport numpy as np\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport tensorflow as tf\nfrom tensorflow.keras import Model, layers, losses, metrics, regularizers, optimizers, initializers\nfrom tensorflow.keras.utils import plot_model\n\n# Default paths.\nSCRIPT_PATH = './LSGAN'\nEXPERIMENT_ID = 'EXP_1'\nMODEL_SAVE_PATH = os.path.join(SCRIPT_PATH, EXPERIMENT_ID)\nif not os.path.exists(MODEL_SAVE_PATH):\n    os.makedirs(MODEL_SAVE_PATH)\nIMG_SAVE_PATH = os.path.join(MODEL_SAVE_PATH, 'generated_img')\nif not os.path.exists(IMG_SAVE_PATH):\n    os.makedirs(IMG_SAVE_PATH)\n\nDEFAULT_TFRECORDS_DIR = '../input/dcgan-dataset'\nDEFAULT_NUM_EPOCHS = 2000\nDEFAULT_LEARNING_RATE = 1e-4\nDEFAULT_BATCH_SIZE = 64\nDEFAULT_SAVE_PERIOD = 15\nDEFAULT_LATENT_DEPTH = 100\n\nIMAGE_WIDTH = 128\nIMAGE_HEIGHT = 128\nIMAGE_CHANNEL = 3\nNUM_INPUT_DATA = 8960\n\nargs = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument('--tfrecords-dir', type=str, dest='tfrecords_dir',\n                        default=DEFAULT_TFRECORDS_DIR,\n                        help='Directory of TFRecords files.')\nparser.add_argument('--num-train-epochs', type=int,\n                        dest='num_train_epochs',\n                        default=DEFAULT_NUM_EPOCHS,\n                        help='Number of times to iterate over all of the '\n                             'training data.')\nparser.add_argument('--learning-rate', type=float,\n                        dest='learning_rate',\n                        default=DEFAULT_LEARNING_RATE,\n                        help='How large a learning rate to use when training.')\nparser.add_argument('--batch-size', type=int,\n                        dest='batch_size',\n                        default=DEFAULT_BATCH_SIZE,\n                        help='How many images to train on at a time.')\nparser.add_argument('--save-period', type=int,\n                        dest='save_period',\n                        default=DEFAULT_SAVE_PERIOD,\n                        help='How many epochs to save ckpt files.')\nparser.add_argument('--latent-depth', type=int,\n                        dest='latent_depth',\n                        default=DEFAULT_LATENT_DEPTH,\n                        help='How many latent variables you have.')\nargs = parser.parse_args('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _parse_function(example):\n    features = tf.io.parse_single_example(\n        example,\n        features={\n            'filename': tf.io.FixedLenFeature([], tf.string, default_value = ''),\n            'image/encoded': tf.io.FixedLenFeature([], tf.string,\n                                                default_value='')\n        })\n    image_encoded = features['image/encoded']\n\n    # Decode the JPEG.\n    image = tf.io.decode_jpeg(image_encoded, channels=3)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_files = glob(os.path.join(args.tfrecords_dir, 'train-*'))\ntrain_dataset = tf.data.TFRecordDataset(train_data_files) \\\n        .map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in train_dataset.take(5):\n    img_np = img.numpy()\n    plt.figure()\n    plt.axis('off')\n    plt.imshow(img_np)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing_data(image):\n    image = tf.image.resize(image, [IMAGE_HEIGHT, IMAGE_WIDTH])\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = train_dataset.map(preprocessing_data) \\\n        .cache() \\\n        .shuffle(NUM_INPUT_DATA) \\\n        .batch(args.batch_size) \\\n        .prefetch(tf.data.experimental.AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_model():\n    inputs = layers.Input(shape=(args.latent_depth,))\n    x = layers.Dense(8*8*512)(inputs)\n    x = layers.Reshape((8, 8, 512))(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n    \n\n    x = layers.Conv2DTranspose(256, 3, 2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02))(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n\n    x = layers.Conv2DTranspose(128, 3, 2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02))(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n\n    x = layers.Conv2DTranspose(64, 3, 2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02))(x)\n    x = layers.BatchNormalization(epsilon=1e-5)(x)\n    x = layers.ReLU()(x)\n\n    x = layers.Conv2DTranspose(3, 3, 2, padding='same', activation = 'sigmoid', kernel_initializer=initializers.RandomNormal(stddev=0.02))(x)\n\n    model = Model(inputs, x, name=\"generator\")\n    model.summary()\n    plot_model(model, to_file=os.path.join(MODEL_SAVE_PATH, \"generator.png\"), show_shapes=True)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_model():\n    inputs = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL))\n    x = layers.Conv2D(32, 5, 2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02))(inputs)\n    x = layers.LeakyReLU(0.2)(x)\n\n    x = layers.Conv2D(64, 5, 2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02))(x)\n    x = layers.LeakyReLU(0.2)(x)\n\n    x = layers.Conv2D(128, 5, 2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02))(x)\n    x = layers.LeakyReLU(0.2)(x)\n\n    x = layers.Conv2D(256, 5, 2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02))(x)\n    x = layers.LeakyReLU(0.2)(x)\n \n    x = layers.Flatten()(x)\n    x = layers.Dense(1)(x)\n \n    model = Model(inputs, x, name=\"discriminator\")\n    model.summary()\n    plot_model(model, to_file=os.path.join(MODEL_SAVE_PATH, \"discriminator.png\"), show_shapes=True)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LSGAN(tf.keras.Model):\n    def __init__(self):\n        super(LSGAN, self).__init__()\n        self.input_layer = layers.Input(shape=(args.latent_depth,))\n        self.generator = generator_model()\n        self.discriminator = discriminator_model()\n        self.mse = losses.MeanSquaredError()\n        self.out = self.call(self.input_layer)\n        super(LSGAN, self).__init__(inputs = self.input_layer, outputs = self.out, name='lsgan')\n \n        self.d_loss_tracker = metrics.Mean(name='losses/d_loss')\n        self.g_loss_tracker = metrics.Mean(name='losses/g_loss')\n        self.d_norm_grad_tracker = metrics.Mean(name='grads/d_norm_grad')\n        self.g_norm_grad_tracker = metrics.Mean(name='grads/g_norm_grad')\n\n    def build(self, input_shape, **kwags):\n        super(LSGAN, self).build(input_shape, **kwags)\n \n    def call(self, inputs, training=False):\n        images = self.generator(inputs, training)\n        outputs = self.discriminator(images, training)\n        return images, outputs\n \n    def compile(self, d_optimizer, g_optimizer, **kwags):\n        super(LSGAN, self).compile(**kwags)\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n \n    @tf.function\n    def train_step(self, real_images):\n        \n        # Sample random points in the latent space\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, args.latent_depth))\n \n        # Decode them to fake images\n        generated_images = self.generator(random_latent_vectors, training=True)\n\n        # Add random noise to the labels - important trick!\n        #labels += 0.05 * tf.random.uniform(tf.shape(labels))\n \n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            r_logit = self.discriminator(real_images, training=True)\n            f_logit = self.discriminator(generated_images, training=True)\n\n            r_loss = self.mse(tf.ones_like(r_logit), r_logit)\n            f_loss = self.mse(tf.zeros_like(f_logit), f_logit)\n            d_loss = r_loss + f_loss\n\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        self.d_loss_tracker.update_state(d_loss)\n        self.d_norm_grad_tracker.update_state(tf.math.log(tf.linalg.global_norm(grads)))\n\n        # Sample random points in the latent space\n        random_latent_vectors = tf.random.normal(shape=(batch_size, args.latent_depth))\n\n        with tf.GradientTape() as tape:\n            # Decode them to fake images\n            generated_images = self.generator(random_latent_vectors, training=True)\n\n            f_logit = self.discriminator(generated_images, training=True)\n            g_loss = self.mse(tf.ones_like(f_logit), f_logit)\n\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        self.g_loss_tracker.update_state(g_loss)\n        self.g_norm_grad_tracker.update_state(tf.math.log(tf.linalg.global_norm(grads)))\n        \n        return {\"losses/d_loss\": self.d_loss_tracker.result(), \"losses/g_loss\": self.g_loss_tracker.result()}\n \n    @property\n    def metrics(self):\n        return [self.d_loss_tracker, self.g_loss_tracker, self.g_norm_grad_tracker, self.d_norm_grad_tracker]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lsgan_model():\n    model = LSGAN()\n    model.summary()\n    plot_model(model, to_file=os.path.join(MODEL_SAVE_PATH, \"lsgan.png\"), show_shapes=True)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lsgan_model()\n\ngenerator_optimizer = tf.keras.optimizers.Adam(lr=args.learning_rate)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(lr=args.learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_noise = tf.random.stateless_normal([4, 1, args.latent_depth], seed = [40, 40])\n\ndef generate_and_save_images(model, epoch):\n\n    plt.figure(figsize=(15,10))\n\n    for i in range(4):\n        images, _ = model(sample_noise[i], training=False)\n        \n        image = images[0, :, :, :]\n        image = np.reshape(image, [IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n\n        plt.subplot(1, 4, i+1)\n        plt.imshow(image)\n        plt.axis('off')\n        plt.title('Epoch_{:04d}'.format(epoch))\n\n    plt.tight_layout()  \n    plt.savefig(os.path.join(IMG_SAVE_PATH, 'image_at_epoch_{:04d}.png'.format(epoch)))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_summary_writer = tf.summary.create_file_writer(os.path.join(MODEL_SAVE_PATH, 'summaries', 'train'))\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def __init__(self, ckpt, manager, period):\n        super(MyCallback, self).__init__()\n        self.period = period\n        self.ckpt = ckpt\n        self.epoch = int(ckpt.epoch)\n        self.manager = manager\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.ckpt.epoch.assign_add(1)\n        self.epoch += 1\n    \n    def on_epoch_end(self, epoch, logs=None):\n        with train_summary_writer.as_default():\n            for metric in self.model.metrics:\n                tf.summary.scalar(metric.name, metric.result(), step=self.epoch)\n          \n        if  self.epoch % self.period == 0:\n            display.clear_output(wait=True)\n            generate_and_save_images(self.model, self.epoch)\n            save_path = self.manager.save()\n            print(\"Saved checkpoint for epoch {}: {}\".format(self.epoch, save_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n#!unzip ngrok-stable-linux-amd64.zip\n\n#LOG_DIR = './LSGAN/EXP_1/summaries/'\n#get_ipython().system_raw(\n#    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n#    .format(LOG_DIR)\n#)\n#get_ipython().system_raw('./ngrok http 6006 &')\n#! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n#    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 model = model)\nmanager = tf.train.CheckpointManager(ckpt, os.path.join(MODEL_SAVE_PATH, 'ckpt'), max_to_keep=3)\nif manager.latest_checkpoint:\n    status = ckpt.restore(manager.latest_checkpoint)\n    status.assert_existing_objects_matched()\n    print(\"Restored from {}\".format(manager.latest_checkpoint))\nelse:\n    print(\"Initializing from scratch.\")\n \nmodel.compile(\n    d_optimizer=discriminator_optimizer,\n    g_optimizer=generator_optimizer,\n)\n \nmy_callback = MyCallback(ckpt, manager, args.save_period)\n\nprint('Start learning!')\nmodel.fit(\n    train_dataset,\n    epochs = args.num_train_epochs,\n    callbacks = [my_callback],\n    initial_epoch = int(ckpt.epoch),\n)\nprint('Learning finished!')\n \n'''\nmodel.evaluate(\n    test_dataset\n)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anim_file = os.path.join(MODEL_SAVE_PATH, 'lsgan.gif')\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n    filenames = glob(os.path.join(IMG_SAVE_PATH, '*.png'))\n    filenames = sorted(filenames)\n    last = -1\n    for i,filename in enumerate(filenames):\n        frame = 2*(i**0.5)\n        if round(frame) > round(last):\n            last = frame\n        else:\n            continue\n        image = imageio.imread(filename)\n        writer.append_data(image)\n    image = imageio.imread(filename)\n    writer.append_data(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display.clear_output(wait=True)\ngenerate_and_save_images(model, int(ckpt.epoch))\n\ntf.saved_model.save(model, os.path.join(MODEL_SAVE_PATH, 'lsgan'))\nprint('lsgan.pb file is created successfully!!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}